{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1SFiBHa8xmO-LG8XloxQXJXI2zSK8ds71",
      "authorship_tag": "ABX9TyOEyL+eic8IR9VokEGBEPHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/budennovsk/Pandas/blob/master/lesson_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark pyngrok"
      ],
      "metadata": {
        "id": "PQ4WYX-kjTJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "spark = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .appName(\"halltape_pyspark_local\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "print(\"Активные Spark сессии:\", spark.sparkContext.uiWebUrl)"
      ],
      "metadata": {
        "id": "yKZNwvNvlBwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# Прочитаем токен из файла token.txt\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/py_spark/data/token.txt\") as f:\n",
        "    auth_token = f.read().strip()\n",
        "\n",
        "import os\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = auth_token\n",
        "\n",
        "# Проверим, что токен установлен\n",
        "print(\"Токен успешно добавлен в переменные окружения.\")\n",
        "public_url = ngrok.connect(4040, \"http\")\n",
        "print(public_url)"
      ],
      "metadata": {
        "id": "z9WUI5iGvzSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Colab Notebooks/py_spark/data/customs_data.csv'"
      ],
      "metadata": {
        "id": "2FAsKa1alPR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCCHmmSwydB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.csv(PATH).show()"
      ],
      "metadata": {
        "id": "DWdCBeIPqm1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(PATH, sep=';', header=True)\n",
        "\n",
        "df.show(truncate=False)\n",
        "\n",
        "# df.show(2, False, True)"
      ],
      "metadata": {
        "id": "ICgGB6VGyegv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = (\n",
        "    df\n",
        "    .withColumnRenamed(\"direction_eng\", \"direction\")\n",
        "    .withColumnRenamed(\"measure_eng\", \"measure\")\n",
        ")\n",
        "\n",
        "result.columns"
      ],
      "metadata": {
        "id": "teSfwzbExE83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select('country').distinct().show(10, truncate=False)"
      ],
      "metadata": {
        "id": "6eTVLUtwyqMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Два варианта написании фильтрации\n",
        "df_de = (\n",
        "    result\n",
        "    .where(F.col('country') == 'DE')\n",
        "    .where(F.col('value').isNotNull())\n",
        ")"
      ],
      "metadata": {
        "id": "sNCm3hDAyv4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_de.show(2, truncate=False)"
      ],
      "metadata": {
        "id": "Kkw4R-bmCqp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = (\n",
        "    df_de\n",
        "    .select(\n",
        "        'month',\n",
        "        'country',\n",
        "        'code',\n",
        "        'value',\n",
        "        'netto',\n",
        "        'quantity',\n",
        "        'region',\n",
        "        'district',\n",
        "        'direction',\n",
        "        'measure',\n",
        "        F.col('load_date').cast('date'),\n",
        "    )\n",
        ")\n",
        "\n",
        "final.show(2, truncate=False)"
      ],
      "metadata": {
        "id": "Mim4CyRuCvjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    final\n",
        "    .coalesce(1)\n",
        "    .write\n",
        "    .format('csv')\n",
        "    .options(header='True', sep=';')\n",
        "    .csv('data/final_one_file')\n",
        ")"
      ],
      "metadata": {
        "id": "-cxvS-FdC5y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CollectExample\").getOrCreate()\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = spark.createDataFrame([\n",
        "    (\"Alice\", 25, \"London\"),\n",
        "    (\"Bob\", 30, \"New York\"),\n",
        "    (\"Charlie\", 35, \"Paris\"),\n",
        "    (\"Diana\", 28, \"Tokyo\")\n",
        "], [\"name\", \"age\", \"city\"])\n",
        "\n",
        "# collect() возвращает список Row объектов\n",
        "all_data = df.collect()\n",
        "print(f\"Тип: {type(all_data)}\")  # <class 'list'>\n",
        "print(f\"Размер: {len(all_data)}\")  # 4\n",
        "\n"
      ],
      "metadata": {
        "id": "iNx4JkjQRIVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "WWY96209KJfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.collect()"
      ],
      "metadata": {
        "id": "xcu6jMpXLCms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gf = df.repartition(1)"
      ],
      "metadata": {
        "id": "gKL2u5_hLOp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gf.show()"
      ],
      "metadata": {
        "id": "FetidLPSN-rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "3TkPT9cvXGVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KvbQUSWnXPc6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}