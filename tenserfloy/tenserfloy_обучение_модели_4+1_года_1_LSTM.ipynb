{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FIu4xsUTwK5O","executionInfo":{"status":"ok","timestamp":1699515795393,"user_tz":-180,"elapsed":49949,"user":{"displayName":"Sergey Zinchenko","userId":"12780695168284482871"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Yw3r0rwf35PdQ-rMf8WdKr1vO2NH21cy"},"outputId":"99edf47c-6eee-440b-8636-d57cbc541ff5"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Задайте максимальное количество столбцов для вывода\n","pd.set_option('display.max_columns', None)\n","\n","# Задайте максимальную ширину вывода для каждого столбца\n","pd.set_option('display.max_colwidth', None)\n","\n","# Генерация данных\n","np.random.seed(0)\n","\n","N_years = 5\n","days = 365 * N_years\n","sku_count = 10\n","\n","# 8.8\n","koef = 8.8\n","\n","\n","\n","\n","# Задаем веса для SKU согласно принципу Парето\n","pareto_weights = (np.arange(sku_count*8, 0, -8) ** -1.5)\n","# pareto_weights = (np.arange(sku_count, 0, -1) ** -1.5)\n","# for i in range(len(pareto_weights)):\n","#     pareto_weights[i] += 0.2\n","# pareto_weights = [weight + 0.2 for weight in pareto_weights_new]\n","# pareto_weights = np.array([weight + 0.2 for weight in pareto_weights_new])\n","\n","\n","pareto_weights /= pareto_weights.sum()\n","# [0.01584834 0.0185618  0.02214873 0.02706056 0.0341002  0.04482588 0.06264608 0.09644994 0.17718986 0.5011686 ]\n","\n","\n","# for i in range(len(pareto_weights)):\n","#     if i == 0:\n","#         pareto_weights[i] += 1000\n","\n","\n","for i in range(len(pareto_weights)):\n","    pareto_weights[i] /= 3\n","# [0.00158483 0.00185618 0.00221487 0.00270606 0.00341002 0.00448259 0.00626461 0.00964499 0.01771899 0.05011686]\n","# print(pareto_weights)\n","# [0.01584834 0.0185618  0.02214873 0.02706056 0.0341002  0.04482588 0.06264608 0.09644994 0.17718986 0.5011686 ]\n","# [0.51584834 0.5185618  0.52214873 0.52706056 0.5341002  0.54482588 0.56264608 0.59644994 0.67718986 1.0011686 ]\n","# [10.01584834  0.0185618   0.02214873  0.02706056  0.0341002   0.04482588 0.06264608  0.09644994  0.17718986  0.5011686 ]\n","# [0.1899093  0.16912702 0.14857482 0.12827856 0.10827111 0.08859582 0.0693126  0.05051026 0.03233547 0.01508503]\n","\n","\n","\n","\n","\n","def calculate_influence(current_sku, other_sku, num_v):\n","    if num_v == 'min_v':\n","        return ((current_sku/other_sku) * 0.6) * koef\n","    else:\n","        x = (0.6 * (current_sku - 10 / 100)) * koef\n","        if x < 0:\n","            return x*(-1)\n","        return (0.6 * (current_sku - 10 / 100))* koef\n","\n","\n","all_sku = pareto_weights\n","\n","# Пройдемся по всем SKU и сравним их\n","def influence():\n","    influences = [[] for _ in range(len(all_sku))]\n","    for i, current_sku in enumerate(all_sku):\n","        for j, other_sku in enumerate(all_sku):\n","            if current_sku != other_sku:\n","                if current_sku < other_sku:\n","                    influence = calculate_influence(current_sku, other_sku, 'min_v')\n","                    influences[i].append(f\"sku_{j+1}_{i+1}: {influence}\")\n","                else:\n","                    influence = calculate_influence(other_sku, current_sku, 'max_v')\n","                    influences[i].append(f\"sku_{j+1}_{i+1}: {influence}\")\n","    return influences\n","\n","# Получаем значения влияния в виде вложенного списка с ключами\n","influences = influence()\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# def generate_promo_intervals():\n","#     starts = np.sort(np.random.choice(np.arange(1, days - 15), size=15, replace=False))\n","#     return [(start, start + 14) for start in starts]\n","\n","\n","def generate_promo_intervals():\n","    new_holiday = []\n","    starts = np.sort(np.random.choice(np.arange(1, 365 - 15), size=5, replace=False))\n","    tuple_date = [(start, start + 14) for start in starts]\n","    for i in range(N_years):\n","        offset = i * 365\n","        for key, value in tuple_date:\n","\n","            new_typle=(key+offset, value+offset)\n","            new_holiday.append(new_typle)\n","\n","    return new_holiday\n","\n","promo_intervals_per_sku = {sku: generate_promo_intervals() for sku in range(1, sku_count + 1)}\n","# print(promo_intervals_per_sku)\n","data = {\n","    'Day': np.tile(np.arange(1, days + 1), sku_count),\n","    'SKU': np.repeat(np.arange(1, sku_count + 1), days),\n","    'Price': np.random.uniform(10, 200, size=days * sku_count),\n","    'Regular Sales': np.abs(np.random.normal(100, 5, days * sku_count) * np.repeat(pareto_weights, days)),\n","    'Promo Sales': np.zeros(days * sku_count),\n","    'Stock': np.random.randint(50, 200, size=days * sku_count)\n","}\n","\n","df = pd.DataFrame(data)\n","\n","\n","\n","new_dicts = []\n","\n","\n","data = promo_intervals_per_sku\n","\n","# Создание нового словаря с замененными ключами\n","new_data = {f\"sku_{key}\": value for key, value in data.items()}\n","\n","\n","# Создание списка ключей из исходного словаря\n","keys = list(data.keys())\n","\n","# Создание списка словарей без одной строки\n","#  new_dicts  список интервалов на каждой строке sku*sku\n","new_dicts = []\n","d = 0\n","for i in range(len(keys)):\n","    d+=1\n","    new_dict = {f\"sku_{key}_{d}\": value for key, value in data.items() if key != keys[i]}\n","    new_dicts.append(new_dict)\n","\n","\n","\n","\n","\n","\n","# Недельная сезонность\n","недельные_коэффициенты = {\n","    0: 0.9,  # Понедельник\n","    1: 1.0,  # Вторник\n","    2: 1.0,  # Среда\n","    3: 1.1,  # Четверг\n","    4: 1.3,  # Пятница\n","    5: 1.5,  # Суббота\n","    6: 1.4   # Воскресенье\n","}\n","# Месячная сезонность\n","# month_coefficients = {\n","#     1: 1.2, 2: 1.1, 3: 1.0, 4: 0.9, 5: 0.9,\n","#     6: 0.9, 7: 1.0, 8: 1.0, 9: 1.1, 10: 1.1,\n","#     11: 1.2, 12: 1.3, 13: 1.2, 14: 1.1, 15: 1.0, 16: 0.9, 17: 0.9,\n","#     18: 0.9, 19: 1.0, 20: 1.0, 21: 1.1, 22: 1.1,\n","#     23: 1.2, 24: 1.3,\n","#     25: 1.2, 26: 1.1, 27: 1.0, 28: 0.9, 29: 0.9, 30: 0.9,\n","#     31: 1.0, 32: 1.0, 33: 1.1, 34: 1.1, 35: 1.2, 36: 1.3\n","# }\n","\n","month_coefficients = {\n","    1: 1.2, 2: 1.1, 3: 1.0, 4: 0.9, 5: 0.9,\n","    6: 0.9, 7: 1.0, 8: 1.0, 9: 1.1, 10: 1.1,\n","    11: 1.2, 12: 1.3\n","}\n","месячные_коэффициенты = {}\n","\n","for i in range(N_years):\n","    offset_yeas = i * 12\n","    for num, indx in month_coefficients.items():\n","        new = num+offset_yeas\n","        месячные_коэффициенты[new]= indx\n","\n","\n","# Праздничная сезонность\n","# праздничные_коэффициенты = {\n","#     1: 1.5,   # Новый год\n","#     45: 1.2,  # День влюбленных\n","#     95: 1.3,  # Пасха\n","#     196: 1.4, # Летние распродажи\n","#     333: 1.7, # Черная пятница\n","#     359: 1.5,  # Рождество\n","#     366: 1.5,   # Новый год\n","#     410: 1.2,  # День влюбленных\n","#     460: 1.3,  # Пасха\n","#     561: 1.4, # Летние распродажи\n","#     698: 1.7, # Черная пятница\n","#     723: 1.5,  # Рождество\n","#     731: 1.5,   # Новый год\n","#     775: 1.2,  # День влюбленных\n","#     825: 1.3,  # Пасха\n","#     926: 1.4, # Летние распродажи\n","#     1063: 1.7, # Черная пятница\n","#     1089: 1.5,  # Рождество\n","# }\n","\n","holiday_coefficients = {\n","    1: 1.5,   # Новый год\n","    7: 1.5,   # Рождество\n","    45: 1.2,  # День влюбленных\n","    95: 1.3,  # Пасха\n","    196: 1.4, # Летние распродажи\n","    333: 1.7, # Черная пятница\n","    365: 1.5,  # Рождество\n","}\n","\n","праздничные_коэффициенты = {}\n","\n","for i in range(N_years):\n","    offset = i * 365\n","    for key, value in holiday_coefficients.items():\n","        new_key = key + offset\n","        праздничные_коэффициенты[new_key] = value\n","\n","\n","\n","\n","def holiday_multiplier(day):\n","\n","    for holiday, boost in праздничные_коэффициенты.items():\n","        days_before_holiday = holiday - day\n","        if 0 <= days_before_holiday <= 6:\n","            return 1 + (boost - 1) * (1 - days_before_holiday / 7)\n","    return 1\n","\n","df['Weekday'] = df['Day'] % 7\n","\n","df['Seasonality'] = df['Weekday'].map(недельные_коэффициенты)\n","df['Month'] = ((df['Day'] - 1) // 30) + 1\n","df['Monthly Seasonality'] = df['Month'].map(месячные_коэффициенты)\n","df['Holiday Boost'] = df['Day'].apply(holiday_multiplier)\n","\n","df['Monthly Seasonality'].fillna(value=1, inplace=True)\n","\n","df['Regular Sales'] *= df['Seasonality'] * df['Monthly Seasonality'] * df['Holiday Boost']\n","# nan_count = df['Monthly Seasonality'].isna().sum()\n","\n","# print(\"Number of NaN values in 'Monthly Seasonality':\", nan_count)\n","\n","# nan_count_h = df['Holiday Boost'].isna().sum()\n","\n","# print(\"Number of NaN values in 'Holiday Boost':\", nan_count_h)\n","# nan_count_q = df['Seasonality'].isna().sum()\n","\n","# print(\"Number of NaN values in 'Seasonality':\", nan_count_q)\n","\n","\n","\n","\n","for sku, intervals in promo_intervals_per_sku.items():\n","\n","    for start, end in intervals:\n","\n","\n","        mask = (df['SKU'] == sku) & (df['Day'] >= start) & (df['Day'] <= end)\n","\n","        df.loc[mask, 'Price'] *= np.random.uniform(0.7, 0.8)\n","        promo_increase = np.abs(np.random.normal(200, 5, np.sum(mask)) * pareto_weights[sku-1])\n","        df.loc[mask, 'Promo Sales'] = promo_increase\n","        df.loc[mask, 'Regular Sales'] = 0\n","\n","        # other_skus_mask = (df['SKU'] != sku) & (df['Day'] >= start) & (df['Day'] <= end)\n","        # df.loc[other_skus_mask, 'Regular Sales'] *= np.random.uniform(0.7, 0.9)\n","\n","\n","df['index_promo'] = ''\n","\n","# Iterate over the 'data' dictionary\n","for dos in new_dicts:\n","    for sku, ranges in dos.items():\n","        for start, end in ranges:\n","            # Expand the range and check if any value matches the 'DAYS' column\n","            matching_days = range(start, end + 1)\n","            df.loc[df['Day'].isin(matching_days), 'index_promo'] = sku\n","\n","for sublist in influences:\n","\n","    for item in sublist:\n","        key, value = item.split(': ')\n","        df.loc[df['index_promo'] == key, 'res_index_promo'] = float(value)\n","# замена nan на 1 чтобы умножить столбцы без изменений\n","df['res_index_promo'].fillna(value=1, inplace=True)\n","# срез максимальных индексов 286 позиция слишком улетела 4 значение\n","# df['res_index_promo'] = df['res_index_promo'].apply(lambda x: 1.7 if x > 1.7 else x)\n","# показ результатов полученных индексов\n","df['result_1'] = df['Regular Sales'] * df['res_index_promo']\n","# регулярные индексы с связью sku*sku\n","\n","\n","df['Regular Sales'] = df['Regular Sales'] * df['res_index_promo']\n","df['Regular_Sales_Promo_Sales'] = df['Regular Sales'] + df['Promo Sales']\n","\n","\n","# print(df.loc[185:200])\n","# index_search = df[df['SKU'] == 10].index[0]\n","# print(index_search)\n","# result = (df['SKU'] == 1).all()\n","\n","# count_zeros_promo = (df['Promo Sales'] == 0).sum()\n","\n","# print(count_zeros_promo,'count_zeros_promo')  # Вывод количества нулей\n","\n","# count_zeros_regul = (df['Regular Sales'] == 0).sum()\n","\n","# print(count_zeros_regul,'count_zeros_Regular Sales')  # Вывод количества нулей\n","# print(sum([count_zeros_promo,count_zeros_regul]), 'сумма нулей')\n","# print(df.shape[0], 'total _df')\n","\n","\n","\n","\n","\n","# Создание модели\n","\n","# print(df.loc[30:50,'Holiday Boost'])\n","\n","\n","\n","for sku in range(1, sku_count + 1):\n","    plt.figure(figsize=(22, 6))\n","    subset = df[df['SKU'] == sku]\n","    plt.plot(subset['Day'], subset['Regular Sales'], label='Regular Sales')\n","    plt.plot(subset['Day'], subset['Promo Sales'], label='Promo Sales', color='red')\n","    plt.title(f\"Sales for SKU {sku}\")\n","    plt.legend()\n","\n","\n","    # Изменение шага на оси x\n","    plt.xticks(range(0, days, 50))\n","    # праздничные_коэффициенты\n","    # Выделение интервалов зеленым цветом\n","     # Выделение интервалов зеленым цветом\n","    interval_colors = ['green'] * sku_count\n","    bound_pr = []\n","    bound_ol = []\n","    for start in праздничные_коэффициенты:\n","        bound_ol.append(start)\n","        if start != 1:\n","            end = start - 6\n","            bound_pr.append((start,end))\n","            plt.axvspan(start, end, facecolor=interval_colors[sku-1], alpha=0.3)\n","\n","\n","\n","    # interval_colors = ['yellow'] * sku_count\n","    # for intervals in new_dicts:\n","    #     for sku_indx, tuple_num in intervals.items():\n","\n","    #         for start, end in tuple_num:\n","    #             plt.axvspan(start, end, facecolor=interval_colors[sku-1], alpha=0.3)\n","\n","    interval_colors = ['yellow'] * sku_count\n","\n","    for sku_indx, tuple_num in new_dicts[sku-1].items():\n","\n","        for start, end in tuple_num:\n","            plt.axvspan(start, end, facecolor=interval_colors[sku-1], alpha=0.3)\n","\n","\n","\n","\n","\n","plt.show()\n","# print(bound_pr,'green')\n","# print(bound_ol, 'ol')\n","# c = df[df['Holiday Boost']>1]['Day'].tolist()\n","# print(c)\n","# print(df.loc[-10:10950])\n","\n","\n","# Суммарные продажи по SKU\n","total_sales_per_sku = df.groupby('SKU')[['Regular Sales', 'Promo Sales']].sum().sum(axis=1)\n","plt.figure(figsize=(12, 6))\n","total_sales_per_sku.plot(kind='bar')\n","plt.title(\"Total Sales for Each SKU\")\n","plt.ylabel(\"Total Sales\")\n","plt.xlabel(\"SKU\")\n","plt.show()\n","\n","\n","\n","\n","\n","\n","# Добавим столбец 'Date', чтобы использовать его для группировки по неделям\n","df['Date'] = pd.to_datetime(df['Day'], origin='2023-01-01', unit='D')\n","\n","# Группируем по SKU и неделям, затем суммируем продажи\n","weekly_sales = df.groupby('SKU').apply(lambda group: group.set_index('Date').resample('W').sum())\n","\n","# Отрисовка графиков недельных продаж для каждого SKU\n","for sku in range(1, sku_count + 1):\n","    plt.figure(figsize=(22, 6))\n","\n","    # Выбор нужного SKU из отсортированных данных\n","    subset = weekly_sales.loc[sku]\n","\n","    # Рисуем график недельных продаж\n","    plt.plot(subset.index, subset['Regular Sales'] + subset['Promo Sales'], label='Total Weekly Sales')\n","    plt.title(f\"Weekly Sales for SKU {sku}\")\n","    plt.ylabel(\"Sales\")\n","    plt.xlabel(\"Week\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","from google.colab import output\n","from tensorflow import keras\n","from sklearn.metrics import mean_squared_error\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.model_selection import train_test_split  # Добавление необходимых библиотек\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from sklearn.metrics import mean_absolute_error\n","from google.colab import files\n","\n","\n","if 'COLAB_TPU_ADDR' not in os.environ:\n","    print('NOT connected to a TPU')\n","else:\n","    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","    print('Connected to TPU: ', tpu_address)\n","  # Инициализация TPU\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","    print('Number of replicas:', strategy.num_replicas_in_sync)\n","\n","# Задайте максимальное количество столбцов для вывода\n","pd.set_option('display.max_columns', None)\n","\n","# Задайте максимальную ширину вывода для каждого столбца\n","pd.set_option('display.max_colwidth', None)\n","\n","# Индексы строк с пропущенными значениями\n","df.copy()\n","\n","epochs = 150\n","sequence_length = 100\n","forecast_days = 365\n","# sku_count = 1\n","\n","\n","indx_len = 1095\n","sku_mse = []\n","sku_mse_year =[]\n","\n","\n","\n","\n","\n","\n","for sku in range(1, sku_count + 1):\n","    '''X_test (200, 100, 3)\n","Y_test (200, 365)'''\n","    # if sku !=9:\n","    #     continue\n","    sale = df[df['SKU'] == sku].head(1460)\n","    sales = sale.copy()\n","\n","    five_year_test = df[df['SKU'] == sku].tail(365)\n","    five_year_test_X = five_year_test.copy()\n","    # if sku == 9:\n","    #             # предположим, что у вас есть DataFrame df\n","    #     sales.to_csv('df.csv')\n","    #     files.download('df.csv')\n","\n","\n","\n","        # Предварительная обработка данных\n","    sales['Regular_Sales_Promo_Sales'] = (sales['Regular_Sales_Promo_Sales'] - sales['Regular_Sales_Promo_Sales'].min()) / (sales['Regular_Sales_Promo_Sales'].max() - sales['Regular_Sales_Promo_Sales'].min())\n","    sales['Price'] = (sales['Price'] - sales['Price'].min()) / (sales['Price'].max() - sales['Price'].min())\n","    sales['Stock'] = (sales['Stock'] - sales['Stock'].min()) / (sales['Stock'].max() - sales['Stock'].min())\n","\n","       # Предварительная обработка данных для 5 года\n","    five_year_test_X['Regular_Sales_Promo_Sales'] = (five_year_test_X['Regular_Sales_Promo_Sales'] - sale['Regular_Sales_Promo_Sales'].min()) / (sale['Regular_Sales_Promo_Sales'].max() - sale['Regular_Sales_Promo_Sales'].min())\n","    five_year_test_X['Price'] = (five_year_test_X['Price'] - sale['Price'].min()) / (sale['Price'].max() - sale['Price'].min())\n","    five_year_test_X['Stock'] = (five_year_test_X['Stock'] - sale['Stock'].min()) / (sale['Stock'].max() - sale['Stock'].min())\n","\n","    X_train = []\n","    y_train = []\n","\n","\n","    X_train_five_year = []\n","\n","    for i in range(len(sales) - sequence_length - forecast_days + 1):\n","        X = sales[['Regular_Sales_Promo_Sales', 'Price', 'Stock']].values[i: i + sequence_length]\n","\n","        X_train.append(X)\n","        y_train.append(sales['Regular_Sales_Promo_Sales'].values[i + sequence_length: i + sequence_length + forecast_days])\n","\n","    for five in range(len(five_year_test_X)- sequence_length +1):\n","        X_year = five_year_test_X[['Regular_Sales_Promo_Sales', 'Price', 'Stock']].values[five: five + sequence_length]\n","        X_train_five_year.append(X_year)\n","\n","\n","\n","    X_train = np.array(X_train)\n","    y_train = np.array(y_train)\n","\n","    X_train_five_year = np.array(X_train_five_year)\n","\n","\n","\n","    # X_train = X_train.reshape(-1, sequence_length, 1)  # Решейпинг для множества временных рядов\n","\n","    # Использование strategy.scope для обучения модели на TPU\n","    with strategy.scope():\n","\n","\n","        model = Sequential([\n","            LSTM(64, input_shape=(sequence_length, 3), return_sequences=True), #return_sequences=True\n","            Dropout(0.2),\n","            LSTM(64, activation='relu'),\n","            Dense(forecast_days)\n","            ])\n","\n","        model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy','mean_squared_error'])\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","\n","    # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f'./log_Tenser_{sku}', histogram_freq=1,embeddings_freq=1)\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', restore_best_weights=True)\n","\n","    model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping],verbose=0)  #tensorboard_callback\n","\n","        # Проверка предсказаний\n","    predictions = model.predict(X_train_five_year)\n","\n","\n","\n","\n","    # Обратное преобразование предсказанных значений\n","    def inverse_transform(y, y_min, y_max):\n","        return y * (y_max - y_min) + y_min\n","\n","    # # Обратное преобразование фактических значений\n","    # y_test_inv = inverse_transform(y_test, sale['Regular_Sales_Promo_Sales'].min(), sale['Regular_Sales_Promo_Sales'].max())\n","    # print('min2',sale['Regular_Sales_Promo_Sales'].min())\n","    # Обратное преобразование предсказанных значений\n","    predictions_inv = inverse_transform(predictions, sale['Regular_Sales_Promo_Sales'].min(), sale['Regular_Sales_Promo_Sales'].max())\n","\n","\n","    # Сравнение фактических значений с предсказанными значениями\n","    # comparison = pd.DataFrame({'Actual': y_test_inv.flatten(), 'Predicted': predictions_inv.flatten()})\n","\n","    # comparison_0 = pd.DataFrame({'Actual': y_test_inv[0], 'Predicted': predictions_inv[0]})\n","\n","    # Вычисление среднеквадратичной ошибки (MSE) между фактическими и предсказанными значениями\n","    # mse_flatten = mean_squared_error(comparison['Actual'], comparison['Predicted'])\n","\n","    # mse_0 = mean_squared_error(comparison_0['Actual'], comparison_0['Predicted'])\n","\n","\n","    # логика на поиск по строчкам максимум MSE\n","\n","\n","    len_pred_365 = [five_year_test['Regular_Sales_Promo_Sales'].values.tolist() for _ in range(len(predictions_inv))]\n","\n","    min_mse_pd = pd.DataFrame({'y_true': len_pred_365, 'predict':predictions_inv.tolist()})\n","    min_mse_pd['MSE'] = min_mse_pd.apply(lambda row: mean_squared_error(row['y_true'], row['predict']), axis=1)\n","    min_row = min_mse_pd.loc[min_mse_pd['MSE'].idxmin()]\n","    indx_min_mse = min_mse_pd['MSE'].idxmin()\n","    min_row_mse = min_row['MSE']\n","    min_row_predict = min_row['predict']\n","\n","\n","\n","    min_mse_pd_0 = pd.DataFrame({'y_true': five_year_test['Regular_Sales_Promo_Sales'].values.tolist(), 'predict':predictions_inv.tolist()[0]})\n","    # min_mse_pd['MSE'] = min_mse_pd.apply(lambda row: mean_squared_error(row['y_true'], row['predict']), axis=1)\n","\n","\n","    # min_row = min_mse_pd.loc[min_mse_pd['MSE'].idxmin()]\n","    # indx_min_mse = min_mse_pd['MSE'].idxmin()\n","    # min_row_mse = min_row['MSE']\n","    # min_row_predict = min_row['predict']\n","    # # print(min_row)\n","    # max_row = min_mse_pd.loc[min_mse_pd['MSE'].idxmax()]\n","    # indx_max_mse = min_mse_pd['MSE'].idxmax()\n","    # max_row_mse = max_row['MSE']\n","    # max_row_predict = max_row['predict']\n","\n","    # # print()\n","    # y_test_inv_min=y_test_inv[indx_min_mse]\n","\n","    # min_mse_pd['MAE'] = min_mse_pd.apply(lambda row: mean_absolute_error(row['y_true'], row['predict']), axis=1)\n","    # min_row_msel_to_mse = min_mse_pd.loc[indx_min_mse,'MAE']\n","\n","    # sku_mse.append([sku, mse_flatten,mse_0,min_row_mse,indx_min_mse,min_row_msel_to_mse,max_row_mse,indx_max_mse, epochs,sequence_length,forecast_days])\n","\n","    # sku_mse_year.append([sku,mean_squared_error(min_mse_pd['y_true'], min_mse_pd['predict'])])\n","\n","\n","\n","\n","    fig = plt.figure(figsize=(22, 12))\n","    # fig.subplots_adjust(hspace=0.5)\n","\n","    ax1 = fig.add_subplot(2, 1, 1)\n","\n","    # ax1.figure(figsize=(22, 6))\n","    ax1.plot(range(len(sale)), sale['Regular_Sales_Promo_Sales'], label='Исходные данные')\n","    ax1.set_xticks(range(0, len(sale), 50))\n","    # plt.xlim(0, 1095)\n","    start  = len(sale)\n","    stop = start + len(predictions_inv[0])\n","\n","    ax1.plot(np.arange(start, stop), five_year_test['Regular_Sales_Promo_Sales'].values.tolist(), label='Тестовые данные прогноза, y_test', color='green')  # Добавление зеленой линии\n","    ax1.plot(np.arange(start, stop), min_row_predict, label='Прогноз, predict', linestyle='dashed')\n","    # plt.xticks(np.arange(start, stop, step=50))\n","    # plt.xlim(start, stop)\n","\n","    ax1.set_xlabel('Дни')\n","    ax1.set_ylabel('Regular_Sales_Promo_Sales')\n","    ax1.set_title(f\"{forecast_days} Days Forecast for SKU {sku}\")\n","    color_change = 999999\n","    start_indx = 0\n","    stop_indx = 0\n","    for _ in range(1,N_years):\n","\n","        stop_indx += 365\n","        start_indx = stop_indx - 365\n","        color_change -= 123456\n","\n","        ax1.axvspan(start_indx, stop_indx, facecolor=f'#{color_change}', alpha=0.5)\n","\n","    # plt.axvspan(1, 365, facecolor='#CCCCCC', alpha=0.5)\n","    # plt.axvspan(366, 730, facecolor='#999999', alpha=0.5)\n","    # plt.axvspan(731, 1095, facecolor='#666666', alpha=0.5)\n","    # plt.axvspan(731, 1095, facecolor='#333333', alpha=0.5)\n","\n","    ax1.legend()\n","    ax2 = fig.add_subplot(2, 1, 2)\n","\n","    ax2.plot(np.arange(0, 365), five_year_test['Regular_Sales_Promo_Sales'].values.tolist(), label='Тестовые данные прогноза, y_test', color='green')  # Добавление зеленой линии\n","    ax2.plot(np.arange(0, 365), min_row_predict, label='Прогноз, predict', linestyle='dashed', color='#FF8C00')\n","    ax2.set_xlabel('Дни')\n","    ax2.set_ylabel('Regular_Sales_Promo_Sales')\n","    ax2.set_title(f\"Масштабированое предсказания модели за 365 дней. SKU {sku}\")\n","\n","     # Выделение интервалов зеленым цветом\n","    interval_colors = '#777777'\n","    bound_pr = []\n","    bound_ol = []\n","    trimmed_dict = dict(list(праздничные_коэффициенты.items())[:7])\n","\n","    for start in trimmed_dict:\n","        bound_ol.append(start)\n","        if start != 1:\n","            if start !=7:\n","                end = start - 6\n","                bound_pr.append((start,end))\n","\n","\n","                plt.axvspan(end,start, color=interval_colors, alpha=0.3)\n","            else:\n","\n","                plt.axvspan(0,7, color=interval_colors, alpha=0.3,label='Праздничные дни')\n","\n","\n","    # plt.xticks(np.arange(start, stop, step=50))\n","    # indx_len+=1095\n","    sku_mse_year.append([sku,min_row_mse,mean_squared_error(min_mse_pd_0['y_true'], min_mse_pd_0['predict']),indx_min_mse])\n","    ax2.legend()\n","    print()\n","plt.show()\n","\n","# res = pd.DataFrame(sku_mse, columns=[[\"   sku\", f\"   MSE_всех строк {predictions_inv.shape}\", \"    MSE_нулевого индекса\", \"   MSE_минимум\", \"   Индекс_MSE_минимума\", \"   MAE_минимум\",\"   MSE_максимум\", \"    Индекс_MSE_максимум\", \"   Эпохи\", \"   Длина_последователностей\",\"   Длина_предсказаний\"]])\n","# result_string = res.to_string(index=False)\n","# print(result_string)\n","\n","print(pd.DataFrame(sku_mse_year, columns=['  SKU','    MSE_MIN','    MSE_0', '    indx_min']))\n"],"metadata":{"id":"R7LXFJeLwfx6","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1j_NFr5kPU7Oxj1BskUPkGT1B81wVjdqY"},"outputId":"1b650b45-c489-4042-b041-5a3871bc8e50","executionInfo":{"status":"ok","timestamp":1699517154128,"user_tz":-180,"elapsed":1358739,"user":{"displayName":"Sergey Zinchenko","userId":"12780695168284482871"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"J-ZUF-1vz4wl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n"],"metadata":{"id":"m5bT1jAxzjfs"}},{"cell_type":"code","source":["# %load_ext tensorboard\n","# %tensorboard --logdir=./log_Tenser_1"],"metadata":{"id":"bkfkKHK_dDGj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OXi4aY_Usq1h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i68x7vp5Yw6S"},"execution_count":null,"outputs":[]}]}