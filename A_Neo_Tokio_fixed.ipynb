{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOxfl6LPOAcMhkw0T3r1+WJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.0 scikit-learn==1.3.0 pandas==2.0.3 lightautoml==0.4.1"
      ],
      "metadata": {
        "id": "S5YX5bROUTUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzoBDyi5SZUB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "39ZYPLD9TfdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "mEOYZE9STpq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "TARGET_NAME= 'target'\n",
        "# Разделим данные на признаки и целевую переменную\n",
        "X = train_df.drop(columns=[TARGET_NAME])\n",
        "y = train_df[TARGET_NAME]\n",
        "\n",
        "# Применим SMOTE к обучающим данным\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Создаем новый DataFrame с сбалансированными данными\n",
        "train_df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "train_df_resampled[TARGET_NAME] = y_resampled\n",
        "\n",
        "# Проверим размеры классов после применения SMOTE\n",
        "print(y_resampled.value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "wENigd0iRO9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import Binarizer\n",
        "\n",
        "# def binarize_features_by_mean(train_df):\n",
        "#     # Создание копии DataFrame, чтобы не изменять исходный\n",
        "#     train_df_copy = train_df.copy()\n",
        "\n",
        "#     # Перебираем все признаки (кроме 'target')\n",
        "#     for column in train_df.columns:\n",
        "#         if column != 'target':  # Исключаем колонку 'target'\n",
        "#             # Вычисляем среднее значение признака\n",
        "#             mean_value = train_df[column].mean()\n",
        "\n",
        "#             # Создаем объект Binarizer с порогом равным среднему значению\n",
        "#             binarizer = Binarizer(threshold=mean_value)\n",
        "\n",
        "#             # Применяем Binarizer к текущему признаку\n",
        "#             train_df_copy[column + '_binarized'] = binarizer.fit_transform(train_df[[column]])\n",
        "\n",
        "#     return train_df_copy\n",
        "\n",
        "\n",
        "# # Применяем функцию\n",
        "# binned_df_train = binarize_features_by_mean(train_df)\n",
        "\n",
        "# binned_df_train.shape"
      ],
      "metadata": {
        "id": "pd_kigmbDgbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "def generate_new_features(train_df):\n",
        "    train_df_copy = train_df.copy()\n",
        "\n",
        "    # Пример генерации новых признаков\n",
        "    train_df_copy['perimeter_to_area'] = train_df_copy['perimeter'] / train_df_copy['area']\n",
        "    train_df_copy['axis_ratio'] = train_df_copy['major_axis'] / train_df_copy['minor_axis']\n",
        "    train_df_copy['area_to_convex'] = train_df_copy['area'] / (train_df_copy['major_axis'] * train_df_copy['minor_axis'])\n",
        "    train_df_copy['compactness_2'] = (train_df_copy['perimeter'] ** 2) / (4 * 3.1416 * train_df_copy['area'])\n",
        "\n",
        "        # Генерация новых признаков\n",
        "    train_df_copy['area_eccentricity'] = train_df_copy['area'] * train_df_copy['eccentricity']\n",
        "    train_df_copy['perimeter_eccentricity'] = train_df_copy['perimeter'] * train_df_copy['eccentricity']\n",
        "    train_df_copy['roundness_solidity'] = train_df_copy['roundness'] * train_df_copy['solidity']\n",
        "    train_df_copy['major_minor_axis_squared'] = (train_df_copy['major_axis'] ** 2) / (train_df_copy['minor_axis'] ** 2)\n",
        "    train_df_copy['corrected_area_axis'] = train_df_copy['area'] / (train_df_copy['major_axis'] + train_df_copy['minor_axis'])\n",
        "    train_df_copy['compactness_roundness'] = train_df_copy['compactness'] * train_df_copy['roundness']\n",
        "    train_df_copy['eccentricity_area_perimeter'] = (train_df_copy['eccentricity'] * train_df_copy['area']) / train_df_copy['perimeter']\n",
        "    # Генерация новых признаков, основанных на важнейших\n",
        "    train_df_copy['minor_axis_shapefactor_1'] = train_df_copy['minor_axis'] * train_df_copy['shapefactor_1']\n",
        "    # train_df_copy['minor_axis_area_to_convex'] = train_df_copy['minor_axis'] * train_df_copy['area_to_convex']\n",
        "    train_df_copy['shapefactor_1_area_to_convex'] = train_df_copy['shapefactor_1'] * train_df_copy['area_to_convex']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # Генерация полиномиальных признаков (степень 2)\n",
        "    # poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    # poly_features = poly.fit_transform(train_df_copy[['area', 'perimeter', 'major_axis', 'minor_axis']])\n",
        "\n",
        "    # # Получаем имена для новых полиномиальных признаков\n",
        "    # poly_columns = poly.get_feature_names_out(['area', 'perimeter', 'major_axis', 'minor_axis'])\n",
        "\n",
        "    # # Создаем DataFrame для полиномиальных признаков\n",
        "    # poly_df = pd.DataFrame(poly_features, columns=poly_columns)\n",
        "\n",
        "    # # Добавляем полиномиальные признаки в исходный DataFrame\n",
        "    # train_df_copy = pd.concat([train_df_copy, poly_df], axis=1)\n",
        "\n",
        "    return train_df_copy\n",
        "\n",
        "\n",
        "# Применяем функцию для генерации новых признаков\n",
        "new_feature = generate_new_features(train_df_resampled)\n",
        "\n",
        "\n",
        "# Применяем функцию для генерации новых признаков\n",
        "new_feature_test = generate_new_features(test_df)\n",
        "\n",
        "\n",
        "# Печатаем результат\n",
        "new_feature.shape\n"
      ],
      "metadata": {
        "id": "gTxIIYJbILak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# def generate_polynomial_features(train_df, degree=2):\n",
        "#     # Создание копии DataFrame, чтобы не изменять исходный\n",
        "#     train_df_copy = train_df.copy()\n",
        "\n",
        "#     # Перебираем все признаки (кроме 'target')\n",
        "#     for column in train_df.columns:\n",
        "#         if column != 'target':  # Исключаем колонку 'target'\n",
        "#             # Получаем данные только для одного признака\n",
        "#             data = train_df[[column]]\n",
        "\n",
        "#             # Создаем объект PolynomialFeatures с заданной степенью\n",
        "#             poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "\n",
        "#             # Применяем PolynomialFeatures\n",
        "#             poly_features = poly.fit_transform(data)\n",
        "\n",
        "#             # Добавляем новые полиномиальные признаки в DataFrame\n",
        "#             poly_columns = [f\"{column}_poly_{i}\" for i in range(poly_features.shape[1])]\n",
        "#             poly_df = pd.DataFrame(poly_features, columns=poly_columns)\n",
        "\n",
        "#             # Добавляем полиномиальные признаки в исходный DataFrame\n",
        "#             train_df_copy = pd.concat([train_df_copy, poly_df], axis=1)\n",
        "\n",
        "#     return train_df_copy\n",
        "\n",
        "\n",
        "\n",
        "# # Применяем функцию для генерации полиномиальных признаков (степень 2)\n",
        "# binned_df_train = generate_polynomial_features(train_df, degree=2)\n",
        "\n",
        "# # Печатаем результат\n",
        "# binned_df_train.shape\n"
      ],
      "metadata": {
        "id": "vS_rHWR7FvhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "def discretize_features(train_df):\n",
        "    # Создание копии DataFrame, чтобы не изменять исходный\n",
        "    train_df_copy = train_df.copy()\n",
        "\n",
        "    # Перебираем все признаки (кроме 'target')\n",
        "    for column in train_df.columns:\n",
        "        if column != 'target':  # Исключаем колонку 'target'\n",
        "            # Применяем KBinsDiscretizer\n",
        "            k_bins = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform',subsample=None)  # 5 интервалов\n",
        "            # Дискретизируем признак\n",
        "            train_df_copy[column + '_discretized'] = k_bins.fit_transform(train_df[[column]]).astype(int)\n",
        "\n",
        "    return train_df_copy\n",
        "\n",
        "# Применяем функцию\n",
        "binned_df_train = discretize_features(new_feature)\n",
        "binned_df_test = discretize_features(new_feature_test)\n",
        "\n",
        "binned_df_train.shape"
      ],
      "metadata": {
        "id": "YqcGhsN_kVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "# def discretize_features(train_df):\n",
        "#     # Создание копии DataFrame, чтобы не изменять исходный\n",
        "#     train_df_copy = train_df.copy()\n",
        "\n",
        "#     # Перебираем все признаки (кроме 'target')\n",
        "#     for column in train_df.columns:\n",
        "#         if column != 'target':  # Исключаем колонку 'target'\n",
        "#             # Применяем KBinsDiscretizer\n",
        "#             k_bins = KBinsDiscretizer(n_bins=5, encode='onehot', strategy='uniform', subsample=None)  # 5 интервалов\n",
        "#             # Дискретизируем признак\n",
        "#             binned_data = k_bins.fit_transform(train_df[[column]])\n",
        "\n",
        "#             # Получаем имена новых колонок для one-hot кодирования\n",
        "#             onehot_columns = [f\"{column}_bin_{i}\" for i in range(binned_data.shape[1])]\n",
        "\n",
        "#             # Преобразуем разреженную матрицу в плотную и добавляем в DataFrame\n",
        "#             binned_df = pd.DataFrame(binned_data.toarray(), columns=onehot_columns)\n",
        "\n",
        "#             # Добавляем новые колонки к DataFrame\n",
        "#             train_df_copy = pd.concat([train_df_copy, binned_df], axis=1)\n",
        "\n",
        "#     return train_df_copy\n",
        "\n",
        "# # Применяем функцию\n",
        "# binned_df_train = discretize_features(train_df)\n",
        "\n",
        "# # Проверяем результат\n",
        "# binned_df_train.shape\n"
      ],
      "metadata": {
        "id": "39JK_5GQAhtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Разделяем данные\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_df, test_df_val = train_test_split(binned_df_train, test_size=0.08, random_state=42, stratify=binned_df_train['target'])"
      ],
      "metadata": {
        "id": "1wvWYSchTr4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "7ekN0T4wTuLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_val.shape"
      ],
      "metadata": {
        "id": "dNLDJPDcX_cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "automl = TabularAutoML(task=Task('binary'),\n",
        "                       timeout=1000,\n",
        "                       cpu_limit=4,\n",
        "                      reader_params={'n_folds': 5, 'random_state': 42})\n",
        "# Выделяем целевую переменную 'Survived'\n",
        "TARGET_NAME = 'target'\n",
        "# Укажем роли переменных (добавим 'drop' для нерелевантных колонок)\n",
        "roles = {'target': TARGET_NAME}  # эти колонки не было в Kaggle версии\n",
        "\n",
        "automl.fit_predict(binned_df_train, roles=roles, verbose=1)\n",
        "\n",
        "# Предсказание на тестовых данных\n",
        "test_pred = automl.predict(binned_df_test)\n",
        "test_pred\n",
        "\n",
        "test_pred_int = (test_pred.data[:, 0]>0.5).astype(int)\n",
        "results_df = pd.DataFrame({\n",
        "    'target': test_pred_int\n",
        "}, index=binned_df_test.index)\n"
      ],
      "metadata": {
        "id": "wv4Q2m3QTxz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "Nbadrps0AxvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "test_roc_auc = roc_auc_score(test_df_val['target']\n",
        "                             , results_df['target'])\n",
        "\n",
        "print(f'ROC AUC на тестовых данных: {test_roc_auc:.4f}')"
      ],
      "metadata": {
        "id": "j5ZFnoCbWEgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_val['target']"
      ],
      "metadata": {
        "id": "ayb_JcCHXFfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df['target']"
      ],
      "metadata": {
        "id": "MbX8MmDRaRr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fast feature importances calculation\n",
        "fast_fi = automl.get_feature_scores('fast')\n",
        "fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (30, 10), grid = True)"
      ],
      "metadata": {
        "id": "BJO-5EFrcsHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_fi"
      ],
      "metadata": {
        "id": "NEORtr_rNqcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df['target'].hist()"
      ],
      "metadata": {
        "id": "l5Jn8jFufjBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "target = 'target'\n",
        "for feature in train_df.columns:\n",
        "    if feature != target:\n",
        "        fig = px.histogram(train_df, x=feature, color=target,\n",
        "                          nbins=30, barmode='overlay')\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "5KOIO3_piCWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "RFfm0iadp4kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns.tolist()"
      ],
      "metadata": {
        "id": "r97FSxgR8n8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv('answers.csv',index=False,header=False)"
      ],
      "metadata": {
        "id": "0e0LzEh2HIjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7e__q3AeVTg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}